{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f27b68d-95eb-4724-8d5b-abb510a9a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553bd1d9-474b-4f56-95c7-5822ef3f809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_files(path):\n",
    "    '''\n",
    "    Creates a list with the names of the images to be processed.\n",
    "    '''\n",
    "    image_files = []\n",
    "    # creates a ScandirIterator aliased as files\n",
    "    with os.scandir(path) as files:\n",
    "        for file in files:\n",
    "            if file.name.endswith('.png'):\n",
    "                # adds only the image files to the list\n",
    "                image_files.append(file.name)\n",
    "    return sorted(image_files)\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    model = VGG16()\n",
    "    model = Model(inputs = model.inputs, outputs = model.output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def recognize_objects(file, path, model):\n",
    "    '''\n",
    "    Recognizes objects in an image file using the VGG16 model.\n",
    "    '''\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(f'{path}/{file}', target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img)\n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3)\n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get object names\n",
    "    objects = model.predict(imgx)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe6885f8-8cdf-47e5-a2f9-384cc656f59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rallypal/.pyenv/versions/lewagon/lib/python3.10/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_184']\n",
      "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "Objects detected in 01.png are:\n",
      "1. chime (13.16%)\n",
      "2. swab (3.56%)\n",
      "3. crutch (3.04%)\n",
      "4. paintbrush (2.51%)\n",
      "5. panpipe (2.42%)\n",
      "6. ladle (2.13%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "Objects detected in 02.png are:\n",
      "1. picket_fence (8.70%)\n",
      "2. fountain (7.79%)\n",
      "3. chain (6.21%)\n",
      "4. padlock (6.20%)\n",
      "5. hook (6.18%)\n",
      "6. pay-phone (4.17%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "Objects detected in 03.png are:\n",
      "1. abaya (19.94%)\n",
      "2. cleaver (19.56%)\n",
      "3. suit (15.61%)\n",
      "4. wardrobe (8.88%)\n",
      "5. trench_coat (4.54%)\n",
      "6. shower_curtain (3.04%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "Objects detected in 04.png are:\n",
      "1. library (26.79%)\n",
      "2. bookshop (17.91%)\n",
      "3. bookcase (14.04%)\n",
      "4. prison (6.88%)\n",
      "5. streetcar (5.72%)\n",
      "6. vending_machine (1.93%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "Objects detected in 05.png are:\n",
      "1. obelisk (17.02%)\n",
      "2. church (11.09%)\n",
      "3. beacon (9.96%)\n",
      "4. flagpole (8.70%)\n",
      "5. megalith (7.42%)\n",
      "6. fountain (5.81%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
      "Objects detected in 06.png are:\n",
      "1. gown (9.39%)\n",
      "2. groom (7.62%)\n",
      "3. totem_pole (4.25%)\n",
      "4. overskirt (4.10%)\n",
      "5. suspension_bridge (3.62%)\n",
      "6. church (2.98%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "Objects detected in 07.png are:\n",
      "1. pole (18.33%)\n",
      "2. totem_pole (11.58%)\n",
      "3. letter_opener (4.94%)\n",
      "4. paintbrush (4.67%)\n",
      "5. chain (4.17%)\n",
      "6. plunger (2.95%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
      "Objects detected in 08.png are:\n",
      "1. vase (16.49%)\n",
      "2. wine_bottle (5.77%)\n",
      "3. limousine (3.19%)\n",
      "4. pitcher (2.81%)\n",
      "5. water_jug (2.60%)\n",
      "6. ashcan (2.31%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "Objects detected in 09.png are:\n",
      "1. fountain (11.76%)\n",
      "2. pedestal (8.78%)\n",
      "3. matchstick (7.67%)\n",
      "4. obelisk (6.95%)\n",
      "5. pole (4.99%)\n",
      "6. candle (4.75%)\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "Objects detected in 10.png are:\n",
      "1. shower_curtain (16.39%)\n",
      "2. wardrobe (11.60%)\n",
      "3. fountain (7.02%)\n",
      "4. wig (6.03%)\n",
      "5. guillotine (4.58%)\n",
      "6. harp (4.41%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"./data\"\n",
    "model = load_model()\n",
    "files = image_files(path)\n",
    "\n",
    "for file in files: \n",
    "    preds= recognize_objects(file, path, model)\n",
    "    top_preds = decode_predictions(preds, top=6)[0]\n",
    "\n",
    "    print(f\"Objects detected in {file} are:\")\n",
    "    for i, (imagenet_id, label, score) in enumerate(top_preds):\n",
    "        print(f\"{i+1}. {label} ({score*100:.2f}%)\")\n",
    "    print()\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
